---
title: "Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training"
collection: publications
permalink: /publication/2025-ACLb
venue: 'Annual Meeting of the Association for Computational Linguistics'
paperurl: 'https://aclanthology.org/2025.acl-long.158.pdf'
link: 'https://aclanthology.org/2025.acl-long.158/'
github: 'https://github.com/RobustNLP/DeRTa'
citation: "Youliang Yuan+, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu. <br><i>ACL'25: Annual Meeting of the Association for Computational Linguistics</i>"
---
